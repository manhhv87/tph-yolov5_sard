# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license
# PCB dataset https://github.com/manhhv87/PCB_Dataset
# Example usage: python train.py --data VisDrone.yaml
# parent
# ‚îú‚îÄ‚îÄ yolov5
# ‚îî‚îÄ‚îÄ datasets
#     ‚îî‚îÄ‚îÄ PCB_Dataset-main  ‚Üê downloads here


# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets  # dataset root dir
train: PCB_Dataset-main/images/train  # train images (relative to 'path')  
val: PCB_Dataset-main/images/train  # val images (relative to 'path')  
test: # test images (optional)  

# Classes
nc: 6  # number of classes
names: ['missing_hole', 'mouse_bite', 'open_circuit', 'short', 'spur', 'spurious_copper']


# Download script/URL (optional) ---------------------------------------------------------------------------------------
download: |
  from utils.general import download, os, Path
  import shutil
  from sklearn.model_selection import train_test_split
  import xml.etree.ElementTree as ET
  from tqdm import tqdm


  path_to_images = '../datasets/PCB_Dataset-main/images/'
  path_to_annotations = '../datasets/PCB_Dataset-main/Annotations/'
  path_to_labels = '../datasets/PCB_Dataset-main/labels/'
  base_dir = Path("../datasets/PCB_Dataset-main")

  # Dictionary that maps class names to IDs
  class_name_to_id_mapping = {"missing_hole": 0,
                              "mouse_bite": 1,
                              "open_circuit": 2,
                              "short": 3,
                              "spur": 4,
                              "spurious_copper": 5}

  def get_subdir(path_to_folder):
    sub_dir = []
    for dir in os.listdir(path_to_folder):
        sub_dir.append(dir)
    return sub_dir

  # Function to get the data from XML Annotation
  def extract_info_from_xml(xml_file):
      root = ET.parse(xml_file).getroot()
      
      # Initialise the info dict 
      info_dict = {}
      info_dict['bboxes'] = []

      # Parse the XML Tree
      for elem in root:
          # Get the file name 
          if elem.tag == "filename":
              info_dict['filename'] = elem.text
              
          # Get the image size
          elif elem.tag == "size":
              image_size = []
              for subelem in elem:
                  image_size.append(int(subelem.text))
              
              info_dict['image_size'] = tuple(image_size)
          
          # Get details of the bounding box 
          elif elem.tag == "object":
              bbox = {}
              for subelem in elem:
                  if subelem.tag == "name":
                      bbox["class"] = subelem.text
                      
                  elif subelem.tag == "bndbox":
                      for subsubelem in subelem:
                          bbox[subsubelem.tag] = int(subsubelem.text)            
              info_dict['bboxes'].append(bbox)
      
      return info_dict

  # Convert the info dict to the required yolo format and write it to disk
  def convert_to_yolov5(info_dict, sub_dir):
      print_buffer = []
      
      # For each bounding box
      for b in info_dict["bboxes"]:        
          try:
              class_id = class_name_to_id_mapping[b["class"]]
          except KeyError:
              print("Invalid Class. Must be one from ", class_name_to_id_mapping.keys())

          # Transform the bbox co-ordinates as per the format required by YOLO v5
          b_center_x = (b["xmin"] + b["xmax"]) / 2 
          b_center_y = (b["ymin"] + b["ymax"]) / 2
          b_width    = (b["xmax"] - b["xmin"])
          b_height   = (b["ymax"] - b["ymin"])
          
          # Normalise the co-ordinates by the dimensions of the image
          image_w, image_h, image_c = info_dict["image_size"]  
          b_center_x /= image_w 
          b_center_y /= image_h 
          b_width    /= image_w 
          b_height   /= image_h 
          
          #Write the bbox details to the file 
          print_buffer.append("{} {:.3f} {:.3f} {:.3f} {:.3f}".format(class_id, b_center_x, b_center_y, b_width, b_height))

      # Name of the file which we have to save 
      save_file_name = os.path.join(path_to_annotations + sub_dir, info_dict["filename"].replace("jpg", "txt"))

      # Save the annotation to disk
      print("\n".join(print_buffer), file= open(save_file_name, "w"))

  def write_ann(sub_dir):
      for _, dir in enumerate(sub_dir):
          an_note = [os.path.join(path_to_annotations + dir, x) for x in os.listdir(path_to_annotations + dir) if x[-3:] == "xml"]
          an_note.sort()

          # Convert and save the annotations
          for ann in tqdm(an_note):
              info_dict = extract_info_from_xml(ann)
              convert_to_yolov5(info_dict, dir)

  def make_dir():        
      list = ['train']
        
      for items in list:
          path_img = os.path.join(path_to_images, items)
          path_ann = os.path.join(path_to_annotations, items)
          os.mkdir(path_img)
          os.mkdir(path_ann)

  def rename_dir(base_path):
      for folder in base_path.iterdir():
          if not folder.is_dir() or folder.name.startswith("."):
              continue
          name = folder.name
          
          if name == 'Annotations':
              new_name = "labels"
              new_folder = folder.parent / new_name
              shutil.move(folder, new_folder)  

  #Utility function to move images 
  def move_files_to_folder(list_of_files, destination_folder):
      for f in list_of_files:
          try:
              shutil.move(f, destination_folder)
          except:
              print(f)
              assert False

  def split_dataset(sub_dir):
      images = []
      annotations = []

      # Read images and annotations
      for _, dir in enumerate(sub_dir):
          img = [os.path.join(path_to_images + dir, x) for x in os.listdir(path_to_images + dir)]
          ann = [os.path.join(path_to_annotations + dir, x) for x in os.listdir(path_to_annotations + dir) if x[-3:] == "txt"]
          annotations += ann
          images += img

      images.sort()
      annotations.sort()

      # Split the dataset into train-valid-test splits 
      train_images, train_annotations = images, annotations

      return train_images, train_annotations

  def create_dataset(sub_dir):
      write_ann(sub_dir)
      make_dir()

      train_images, train_annotations = split_dataset(sub_dir)      

      # Move the splits into their folders
      move_files_to_folder(train_images, path_to_images + 'train/')
      move_files_to_folder(train_annotations, path_to_annotations + 'train/')    

  # Download
  dir = Path(yaml['path'])  # dataset root dir
  urls = ['https://github.com/manhhv87/PCB_Dataset/archive/refs/heads/main.zip']
  download(urls, dir=dir)

  # Convert  
  create_dataset(get_subdir(path_to_images))  # convert pcb annotations to YOLO labels 
  rename_dir(base_dir)   


